{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e1b78-3ffa-4003-ab40-92913d4c4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this llm or model is being design using langchain and ollama framework to run the llm locally but it takes input from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04eaed9c-db80-4de1-8486-91eabc27a348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-ollama) (0.5.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.60 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-ollama) (0.3.65)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.10.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (2.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.60->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\shive\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-ollama\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433cd0af-6a10-48f9-828b-9aa34a09d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Regarding what topic you are eager to ask now:  Do the job of engineers in danger, due to the evolution of generative ai, explain.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the whole response is: \n",
      " content=\"The increasing presence and capabilities of Generative AI (GANs) pose significant challenges to various professions, including engineering, potentially putting some jobs at risk or changing the nature of others. Here are a few aspects where job changes or risks can be observed:\\n\\n1. **Design and Prototyping**: With advancements in generative design tools like those using GANs or Generative adversarial networks (GAN), AI-assisted designs become increasingly realistic, capable to replicate human style as well. This can make traditional human-designed prototypes less sought after for certain projects, potentially reducing the demand for some designers.\\n\\n2. **Testing and Validation**: Automated testing frameworks utilizing machine learning and natural language processing could enable quicker identification of software or hardware defects by simulating all possible states of a given program, inputting the results into code that will check those predicted values against recorded data on known bugs. The need for extensive human-based manual validation in these environments could gradually dwindle.\\n\\n3. **Code Completion**: Many newer code completion tools, especially those that use advanced NLP and AI algorithms such as transformers, significantly simplify the process of coding, offering many of the capabilities previously done by individual engineers within a team to other team members and sometimes outside developers for integration with legacy software or platforms designed several years back.\\n\\n4. **Technical Documentation**: Many current documentation tools have adopted natural language processing (NLP), similar to GANs and AI algorithms. This could enable automated summarization of text documents, translation of foreign languages into English based on patterns learned from large volumes of text data provided by companies' content management systems. \\n\\nHowever, it's worth noting that advancements in generative AI also offer potential solutions and opportunities:\\n\\n- **Increasing efficiency**: By automating certain tasks, engineers can focus on higher-value tasks requiring human expertise.\\n- **Enhancing design capabilities**: Generative AI tools can augment the creativity of designers, allowing for faster iteration and exploration of ideas.\\n\\nMoreover, new areas will likely emerge due to GANs' capabilities in image processing and 3D rendering:\\n\\n- **Design Synthesis**: Generative models could enable engineers to create fully functional prototypes with reduced data usage compared to more traditional methods.\\n  \\nThese are just a few areas where generative AI is having significant effects. As technology evolves, we're likely to see the field develop new standards that require workers' versatility and creative problem-solving capabilities.\" additional_kwargs={} response_metadata={'model': 'llama3.2:3b', 'created_at': '2025-06-20T10:46:39.5424619Z', 'done': True, 'done_reason': 'stop', 'total_duration': 48301561000, 'load_duration': 7995684900, 'prompt_eval_count': 44, 'prompt_eval_duration': 3656366200, 'eval_count': 479, 'eval_duration': 36611934400, 'model_name': 'llama3.2:3b'} id='run--fba55ca5-a26b-4088-bbc5-22608a8d3940-0' usage_metadata={'input_tokens': 44, 'output_tokens': 479, 'total_tokens': 523} \n",
      "\n",
      "the content part: \n",
      " The increasing presence and capabilities of Generative AI (GANs) pose significant challenges to various professions, including engineering, potentially putting some jobs at risk or changing the nature of others. Here are a few aspects where job changes or risks can be observed:\n",
      "\n",
      "1. **Design and Prototyping**: With advancements in generative design tools like those using GANs or Generative adversarial networks (GAN), AI-assisted designs become increasingly realistic, capable to replicate human style as well. This can make traditional human-designed prototypes less sought after for certain projects, potentially reducing the demand for some designers.\n",
      "\n",
      "2. **Testing and Validation**: Automated testing frameworks utilizing machine learning and natural language processing could enable quicker identification of software or hardware defects by simulating all possible states of a given program, inputting the results into code that will check those predicted values against recorded data on known bugs. The need for extensive human-based manual validation in these environments could gradually dwindle.\n",
      "\n",
      "3. **Code Completion**: Many newer code completion tools, especially those that use advanced NLP and AI algorithms such as transformers, significantly simplify the process of coding, offering many of the capabilities previously done by individual engineers within a team to other team members and sometimes outside developers for integration with legacy software or platforms designed several years back.\n",
      "\n",
      "4. **Technical Documentation**: Many current documentation tools have adopted natural language processing (NLP), similar to GANs and AI algorithms. This could enable automated summarization of text documents, translation of foreign languages into English based on patterns learned from large volumes of text data provided by companies' content management systems. \n",
      "\n",
      "However, it's worth noting that advancements in generative AI also offer potential solutions and opportunities:\n",
      "\n",
      "- **Increasing efficiency**: By automating certain tasks, engineers can focus on higher-value tasks requiring human expertise.\n",
      "- **Enhancing design capabilities**: Generative AI tools can augment the creativity of designers, allowing for faster iteration and exploration of ideas.\n",
      "\n",
      "Moreover, new areas will likely emerge due to GANs' capabilities in image processing and 3D rendering:\n",
      "\n",
      "- **Design Synthesis**: Generative models could enable engineers to create fully functional prototypes with reduced data usage compared to more traditional methods.\n",
      "  \n",
      "These are just a few areas where generative AI is having significant effects. As technology evolves, we're likely to see the field develop new standards that require workers' versatility and creative problem-solving capabilities. \n",
      "\n",
      "the metadata part: \n",
      " {'model': 'llama3.2:3b', 'created_at': '2025-06-20T10:46:39.5424619Z', 'done': True, 'done_reason': 'stop', 'total_duration': 48301561000, 'load_duration': 7995684900, 'prompt_eval_count': 44, 'prompt_eval_duration': 3656366200, 'eval_count': 479, 'eval_duration': 36611934400, 'model_name': 'llama3.2:3b'} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'token_usage, model, model_version, and other metadata,\\nollama_parameters: A dictionary of the parameters (like temperature, max_tokens, top_k, top_p, seed, etc.), and\\nfinish_reason: Why the model stopped generating (e.g., \"stop\" for natural end, \"length\" for hitting max_tokens).'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\"\"\"The ChatOllama class is a specific implementation within LangChain that allows you to interact\n",
    "with large language models (LLMs) served locally via the Ollama platform. It provides a standardized\n",
    "interface for sending prompts and receiving responses from these models. \"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\"\"\"Another important module as it is load variable environment from your .env file, this file is\n",
    "generally used for storing the API keys.\"\"\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\"\"\"calling the .env file to get the API key.\"\"\"\n",
    "\n",
    "model = ChatOllama(\n",
    "    model = \"llama3.2:3b\",\n",
    "    temperature = 1.5,\n",
    "    max_tokens = 2048\n",
    ")\n",
    "\n",
    "\"\"\"creates an instance to connect with the required model of the ollama and also set the other variables\n",
    "like temperature and max_tokens for the randomness(ranging from 0 to 2) and maximum number output tokens\n",
    "respectively, 0 for more repetitive and deterministic while 2 for most random and creative.\"\"\"\n",
    "\n",
    "text = input(\"Regarding what topic you are eager to ask now: \")\n",
    "\n",
    "\"\"\"user interface to ask question.\"\"\"\n",
    "\n",
    "result = model.invoke(text)\n",
    "\n",
    "\"\"\"invoke method is used to send the prompt to the model and get the response back and stored in result.\"\"\"\n",
    "\n",
    "print(\"the whole response is: \\n\", result, \"\\n\")\n",
    "\n",
    "\"\"\"it contains content and response_metadata (which holds the \"meta-model\" information you're likely thinking of).\"\"\"\n",
    "\n",
    "print(\"the content part: \\n\", result.content, \"\\n\")\n",
    "\n",
    "print(\"the metadata part: \\n\", result.response_metadata,\"\\n\")\n",
    "\n",
    "\"\"\"token_usage, model, model_version, and other metadata,\n",
    "ollama_parameters: A dictionary of the parameters (like temperature, max_tokens, top_k, top_p, seed, etc.), and\n",
    "finish_reason: Why the model stopped generating (e.g., \"stop\" for natural end, \"length\" for hitting max_tokens).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a10b18-b62f-4ef0-b1b0-723653e67bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
